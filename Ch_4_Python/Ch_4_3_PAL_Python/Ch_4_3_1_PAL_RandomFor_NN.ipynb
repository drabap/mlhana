{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Random Forests und neuronale Netze trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest trainieren\n",
    "-- Aufteilen der Grunddaten in Trainings- und Testdaten\n",
    "-- Trainieren eines Random Forest\n",
    "-- Evaluieren des Modells auf der Testmenge\n",
    "- Neuronales Netz trainieren\n",
    "-- Aufteilen der Grunddaten in Trainings- und Testdaten\n",
    "-- Trainieren und Evaluieren des neuronalen Netzes\n",
    "-- Hyperparameter optimieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verbindung zur HANA\n",
    "from hana_ml import dataframe\n",
    "\n",
    "connection = dataframe.ConnectionContext(KEY = 'DEV')\n",
    "\n",
    "# CHURN laden\n",
    "g_df_churn = connection.table('CHURN',\n",
    "                                   schema = 'ML_DATA')\n",
    "\n",
    "g_df_churn.head(20).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufteilen in Grund- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Daten partitionieren\n",
    "from hana_ml.algorithms.pal import partition\n",
    "\n",
    "g_df_train, g_df_test, g_df_valid = partition.train_test_val_split( \n",
    "                                                    data = g_df_churn,\n",
    "                                                    id_column = 'CUSTOMERID', \n",
    "                                                    partition_method = 'stratified',\n",
    "                                                    training_percentage = 0.6, \n",
    "                                                    validation_percentage = 0.0,\n",
    "                                                    testing_percentage = 0.4,\n",
    "                                                    stratified_column = 'EXITED' \n",
    "   )\n",
    "\n",
    "# Anteil Kündigungen je nach Referenzmenge zählen\n",
    "# Gesamtmenge\n",
    "g_df_churn.agg([('count','CUSTOMERID','count_customer')] ,\n",
    "               group_by = ['EXITED']).collect()\n",
    "\n",
    "# Trainingsdaten\n",
    "# g_df_train.agg([('count','CUSTOMERID','count_customer')], \n",
    "#          group_by = ['EXITED']).collect()\n",
    "\n",
    "# Testdaten\n",
    "# g_df_test.agg([('count','CUSTOMERID','count_customer')] , group_by = ['EXITED']).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainieren des Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainieren des Random Forest\n",
    "from hana_ml.algorithms.pal.trees import *\n",
    "rfc = RDTClassifier( \n",
    "                             n_estimators = 10,\n",
    "                             max_features = 10, random_state = 2,\n",
    "                            split_threshold = 0.00001,\n",
    "                            categorical_variable = ['EXITED'], \n",
    "                            strata = [(0,0.5),(1,0.5)], \n",
    "                            thread_ratio = 1.0 \n",
    "                    )\n",
    "\n",
    "l_features = ['CREDITSCORE','GEOGRAPHY','GENDER','AGE',\n",
    "              'TENURE','BALANCE','NUMOFPRODUCTS',\n",
    "              'HASCRCARD','ISACTIVEMEMBER','ESTIMATEDSALARY']\n",
    "\n",
    "rfc.fit(data = g_df_train,\n",
    "        key = 'CUSTOMERID',\n",
    "        features = l_features, \n",
    "        label = 'EXITED')\n",
    "\n",
    "# rfc.model_.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusatz: Instanzattribute nach Training\n",
    "# rfc.model_.collect()\n",
    "\n",
    "# rfc.feature_importances_.collect()\n",
    "\n",
    "# rfc.oob_error_.collect()\n",
    "\n",
    "rfc.confusion_matrix_.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell anwenden auf Testmenge und Konfusionsmatrix berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict anwenden auf Testmenge\n",
    "l_features = ['CREDITSCORE','GEOGRAPHY','GENDER','AGE',\n",
    "                  'TENURE','BALANCE','NUMOFPRODUCTS',\n",
    "                  'HASCRCARD','ISACTIVEMEMBER','ESTIMATEDSALARY']\n",
    "\n",
    "g_df_predict_test = rfc.predict(data = g_df_test,\n",
    "                                key = 'CUSTOMERID',\n",
    "                                features = l_features)\n",
    "\n",
    "g_df_predict_test.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrektklassifikationsrate berechnen (engl.: Accuracy Score)\n",
    "rfc.score(data = g_df_test,\n",
    "          key = 'CUSTOMERID',\n",
    "          features = l_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verknüpfen von Prognoseergebnis und Testmenge\n",
    "col_select = [('P.CUSTOMERID','CUSTOMERID'), \n",
    "              ('P.SCORE','SCORE'), \n",
    "              ('A.EXITED','EXITED')]\n",
    "\n",
    "l_df_compare = g_df_predict_test.alias('P').join(\n",
    "                                          other = g_df_test.alias('A'),\n",
    "                                          condition = 'P.CUSTOMERID = A.CUSTOMERID',\n",
    "                                          select = col_select)\n",
    "\n",
    "l_df_compare = l_df_compare.cast('SCORE', \n",
    "                             'INT').rename_columns({'SCORE': 'PREDICTED'})\n",
    "\n",
    "l_df_compare.head(20).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einschub: Aggregieren auf Spalte EXITED, SCORE => gleiches Ergebnis wie Konfusionsmatrix\n",
    "l_df_agg = l_df_compare.agg([('count','CUSTOMERID','COUNT')], group_by = ['EXITED','PREDICTED'])\n",
    "\n",
    "l_df_agg.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Konfusionsmatrix und Erfolgskennzahlen\n",
    "from hana_ml.algorithms.pal.metrics import confusion_matrix\n",
    "\n",
    "(df_confusion_matrix, df_class_report) = confusion_matrix(\n",
    "                                       data = l_df_compare, \n",
    "                                       key = 'CUSTOMERID',\n",
    "                                       label_true = 'EXITED',\n",
    "                                       label_pred = 'PREDICTED')\n",
    "\n",
    "df_confusion_matrix.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusatz: Gütekriterien ermittelt mit der Testmenge\n",
    "df_class_report.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot-Funktion für die Konfusionsmatrix\n",
    "# Zeile: Korrekte Klasse (actual class)\n",
    "# Spalte: Vorhergesagte Klasse (predicted class), wie in Geron p. 91\n",
    "# index = EXITED => bleibt in Zeile => Zeile entspricht tatsächlichem Wert\n",
    "# columns = PREDICTED => wird zu Spalte => Spalte entspricht Vorhersage aus Spalte PREDICTED\n",
    "df_confusion_matrix.pivot_table(index = 'EXITED',\n",
    "                             columns = 'PREDICTED',\n",
    "                             values = 'COUNT').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einfluss der Features untersuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevanz der Variablen für die Prognose ausgeben\n",
    "df_feature_importance = rfc.feature_importances_.sort(\n",
    "    'IMPORTANCE',desc = True)\n",
    "\n",
    "df_feature_importance.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotten der Variablenwichtigkeit\n",
    "from hana_ml.visualizers.eda import EDAVisualizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig_barplot = plt.figure(figsize = (18,6))\n",
    "ax1 = fig_barplot.add_subplot(121)\n",
    "eda = EDAVisualizer(ax1)\n",
    "\n",
    "ax1, bar_data = eda.bar_plot(\n",
    "    data = df_feature_importance,\n",
    "    column = 'VARIABLE_NAME',\n",
    "    aggregation = {'IMPORTANCE':'avg'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronale Netze trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsmenge mit ausgewogener Klassenverteilung erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsmenge mit ausgewogener Klassenverteilung\n",
    "\n",
    "l_df_train_0 = g_df_churn.filter('EXITED = 0').head(1000)\n",
    "l_df_train_1 = g_df_churn.filter('EXITED = 1').head(1000)\n",
    "\n",
    "l_df_id_train = l_df_train_0.union(\n",
    "    l_df_train_1).select([('CUSTOMERID','ID')])\n",
    "\n",
    "l_df_id_train_mark = l_df_id_train.select(\n",
    "    '*',('1','MARKER_TRAIN'))\n",
    "\n",
    "# Left outer JOIN auf Grundgesamtheit\n",
    "l_df_id_split = g_df_churn.alias('CH').join(\n",
    "                                             other = l_df_id_train_mark.alias('TM'),\n",
    "                                             condition = 'CH.CUSTOMERID = TM.ID',\n",
    "                                             how = 'outer' )\n",
    "\n",
    "# Berechnete Spalte mit coalesce (MARKER_TRAIN, 0): \n",
    "#   => Flag 1 bei Sätzen, die in Trainingsmenge l_df_id_train_mark sind\n",
    "#   => Flag 0 bei Sätzen ohne JOIN-Partner, also alle, die nicht in l_df_id_train_mark sind\n",
    "l_df_churn_split = l_df_id_split.select('*',\n",
    "                                        ('COALESCE(MARKER_TRAIN,0)','TRAIN_SET')\n",
    "                                        )\n",
    "\n",
    "g_df_train_nn = l_df_churn_split.filter(\"TRAIN_SET = 1\")\n",
    "\n",
    "g_df_test_nn = l_df_churn_split.filter(\"TRAIN_SET = 0\")\n",
    "\n",
    "# Zählen der Kündigenden in Training- und Testmenge\n",
    "g_df_train_nn.agg([('count','EXITED','COUNT')],\n",
    "                  group_by = ['EXITED']).collect()\n",
    "# test_nn.agg([('count','EXITED','COUNT')],group_by = ['EXITED']).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training des neuronalen Netzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das neuronale Netz trainieren\n",
    "from hana_ml.algorithms.pal.neural_network import *\n",
    "\n",
    "mlp_c = MLPClassifier(hidden_layer_size = (30,15,10,5),\n",
    "                      activation = 'sigmoid_symmetric', \n",
    "                      output_activation = 'sigmoid_symmetric',\n",
    "                      training_style = 'batch',\n",
    "                      max_iter = 1000,\n",
    "                      normalization = 'z-transform',\n",
    "                      weight_init = 'normal',\n",
    "                      thread_ratio = 0.3, \n",
    "                      categorical_variable = ['EXITED',\n",
    "                                            'HASCRCARD',\n",
    "                                            'ISACTIVEMEMBER']\n",
    "                     )\n",
    "\n",
    "l_features = ['CREDITSCORE','GEOGRAPHY','GENDER','AGE',\n",
    "                  'TENURE','BALANCE','NUMOFPRODUCTS',\n",
    "                  'HASCRCARD','ISACTIVEMEMBER','ESTIMATEDSALARY']\n",
    "\n",
    "\n",
    "\n",
    "mlp_c.fit(data = g_df_train_nn,\n",
    "         key = 'CUSTOMERID',\n",
    "         features = l_features,\n",
    "         label = 'EXITED')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einschub: Das fertige Modell\n",
    "mlp_c.model_.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anwenden des Modells auf die Testdaten und Berechnung der Konfusionsmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwenden des neuronalen Netzes auf die Testdaten\n",
    "g_df_mlp_prediction, test_stat = mlp_c.predict(\n",
    "                                          data = g_df_test_nn,\n",
    "                                          key = 'CUSTOMERID',\n",
    "                                          features = l_features \n",
    "                                         )\n",
    "\n",
    "g_df_mlp_prediction.collect()\n",
    "# mlp_prediction.agg([('count','CUSTOMERID','count_customer')] , group_by = ['TARGET']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfusionsmatrix für das neuronale Netz\n",
    "# Verknüpfen von Prognoseergebnis und Testmenge\n",
    "col_select = [('P.CUSTOMERID','CUSTOMERID'), \n",
    "              ('P.TARGET','TARGET'),\n",
    "              ('A.EXITED','EXITED')]\n",
    "\n",
    "l_df_compare_mlp = g_df_mlp_prediction.alias('P').join(\n",
    "                                          other = g_df_test_nn.alias('A'),\n",
    "                                          condition = 'P.CUSTOMERID = A.CUSTOMERID',\n",
    "                                          select = col_select)\n",
    "\n",
    "l_df_compare_mlp = l_df_compare_mlp.cast('TARGET', 'INT')\n",
    "l_df_compare_mlp = l_df_compare_mlp.rename_columns(\n",
    "    {'TARGET': 'PREDICTED'})\n",
    "\n",
    "# Berechnung der Konfusionsmatrix und Erfolgskennzahlen\n",
    "from hana_ml.algorithms.pal.metrics import confusion_matrix\n",
    "\n",
    "(df_conf_matrix_nn, df_class_rep_nn)  = confusion_matrix( \n",
    "                                       data = l_df_compare_mlp, \n",
    "                                       key = 'CUSTOMERID',\n",
    "                                       label_true = 'EXITED',\n",
    "                                       label_pred = 'PREDICTED')\n",
    "\n",
    "df_conf_matrix_nn.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_rep_nn.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimieren bei neuronalen Netzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voraussetzung: Verbindung zur HANA steht\n",
    "# Splitting in Trainingsmenge und Testmenge wurde durchgeführt\n",
    "# Variable g_df_train_nn und g_df_test_nn sind gefüllt\n",
    "g_df_train_nn.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainieren mit Optimierung der Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training mit Optimierung der Hyperparameter\n",
    "from hana_ml.algorithms.pal.neural_network import *\n",
    "\n",
    "# Mögliche Werte für Netztopologie\n",
    "hidden_layer_opt = [(30,20,10,5),(10,10,5,5),(30,20,10),(10,5)]\n",
    "\n",
    "# act_opts = ['tanh', 'sigmoid_symmetric']\n",
    "# act_out_opts = ['tanh', 'sigmoid_symmetric']\n",
    "\n",
    "\n",
    "mlp_c_opt = MLPClassifier( \n",
    "                      # hidden_layer_size = (10,10,5,5),\n",
    "                      hidden_layer_size_options = hidden_layer_opt,\n",
    "                      activation = 'sigmoid_symmetric',\n",
    "                      #activation_options = act_opts, \n",
    "                      output_activation = 'sigmoid_symmetric',\n",
    "                      #output_activation_options = act_out_opts,\n",
    "                      training_style = 'batch', # oder batch\n",
    "                      max_iter = 1000,\n",
    "                      normalization = 'z-transform',\n",
    "                      weight_init = 'normal',\n",
    "                      thread_ratio = 0.3, \n",
    "                      categorical_variable = ['EXITED',\n",
    "                                            'HASCRCARD',\n",
    "                                            'ISACTIVEMEMBER'],\n",
    "                      resampling_method = 'cv', # oder stratified_cv, bootstrap, stratified_bootstrap\n",
    "                      fold_num = 4,\n",
    "                      evaluation_metric = 'f1_score', # oder accuracy, auc_onevsrest, auc_pairwise\n",
    "                      search_strategy = 'grid',\n",
    "                      progress_indicator_id = 'TEST'    \n",
    "                     )\n",
    "\n",
    "l_features = ['CREDITSCORE','GEOGRAPHY','GENDER','AGE',\n",
    "                  'TENURE','BALANCE','NUMOFPRODUCTS',\n",
    "                  'HASCRCARD','ISACTIVEMEMBER','ESTIMATEDSALARY']\n",
    "\n",
    "\n",
    "\n",
    "mlp_c_opt.fit( data = g_df_train_nn,\n",
    "         key = 'CUSTOMERID',\n",
    "         features = l_features,\n",
    "         label = 'EXITED' )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusatz: Ausgabe der Statistiken zur Parameteroptimierung\n",
    "mlp_c_opt.stats_.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beste Wahl der Hyperparameter ausgeben\n",
    "mlp_c_opt.optim_param_.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusatz: Log des Trainings ausgeben\n",
    "mlp_c_opt.train_log_.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zusatz: Anwenden des Modells mit optimierten Hyperparameter auf die Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwenden des neuronalen Netzes mit den optimierten Hyperparametern auf die Testdaten\n",
    "g_mlp_opt_pred, test_stat = mlp_c_opt.predict(\n",
    "                                          data = g_df_test_nn,\n",
    "                                          key = 'CUSTOMERID',\n",
    "                                          features = l_features \n",
    "                                         )\n",
    "\n",
    "\n",
    "# mlp_prediction.agg([('count','CUSTOMERID','count_customer')] , group_by = ['TARGET']).collect()\n",
    "# Konfusionsmatrix für das neuronale Netz\n",
    "# Verknüpfen von Prognoseergebnis und Testmenge\n",
    "col_select = [('P.CUSTOMERID','CUSTOMERID'), \n",
    "              ('P.TARGET','TARGET'),\n",
    "              ('A.EXITED','EXITED')]\n",
    "\n",
    "l_df_compare_mlp_opt = g_mlp_opt_pred.alias('P').join(\n",
    "                                          other = g_df_test_nn.alias('A'),\n",
    "                                          condition = 'P.CUSTOMERID = A.CUSTOMERID',\n",
    "                                          select = col_select)\n",
    "\n",
    "l_df_compare_mlp_opt = l_df_compare_mlp_opt.cast('TARGET', 'INT')\n",
    "l_df_compare_mlp_opt = l_df_compare_mlp_opt.rename_columns(\n",
    "    {'TARGET': 'PREDICTED'})\n",
    "\n",
    "# Berechnung der Konfusionsmatrix und Erfolgskennzahlen\n",
    "from hana_ml.algorithms.pal.metrics import confusion_matrix\n",
    "\n",
    "(df_conf_matrix_mlp_opt, df_class_rep_mlp_opt)  = confusion_matrix( \n",
    "                                       data = l_df_compare_mlp_opt, \n",
    "                                       key = 'CUSTOMERID',\n",
    "                                       label_true = 'EXITED',\n",
    "                                       label_pred = 'PREDICTED')\n",
    "\n",
    "df_conf_matrix_mlp_opt.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_rep_mlp_opt.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
